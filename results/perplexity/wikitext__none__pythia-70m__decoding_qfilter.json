{
  "model": "EleutherAI/pythia-70m",
  "dataset": "wikitext",
  "subset": null,
  "sample_idx": null,
  "tokens": 286220,
  "loss": null,
  "ppl": null,
  "press": "decoding_qfilter",
  "compression_ratio": null,
  "attn_implementation": null,
  "speed_tokens_per_s": null,
  "peak_mem_bytes": null,
  "residual_mem_bytes": null,
  "context_tokens": null,
  "context_tokens_truncated": null,
  "error": "Could not load Q-filters for pythia-70m. Available models: ['Llama-3.1-8B-Instruct', 'Llama-3.2-1B-Instruct', 'Llama-3.2-3B-Instruct', 'Llama-3.2-3B', 'Llama-3.1-8B', 'Llama-3.1-70B-Instruct', 'Llama-3.1-70B', 'Meta-Llama-3.1-405B', 'Mistral-Small-24B-Instruct-2501', 'phi-4', 'Llama-3.2-1B', 'Qwen2.5-7B', 'Qwen2.5-7B-Instruct', 'DeepSeek-R1-Distill-Llama-8B', 'DeepSeek-R1-Distill-Qwen-1.5B']"
}